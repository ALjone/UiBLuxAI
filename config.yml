#Training
max_episodes: 10000000
print_freq: 100        # print avg reward in the interval (in episodes)

#PPO 
batch_size: 512
actor_lr: 0.0003
critic_lr: 0.0003
gamma: 0.99
epochs_per_batch: 4
eps_clip: 0.1
lmbda: 0.95

#Other
device: cuda
path: None #model.t
save_path: model.t